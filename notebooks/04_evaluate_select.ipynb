{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2169e7",
   "metadata": {},
   "source": [
    "# 04. Evaluation & Visualization\n",
    "\n",
    "Deep dive into model performance: Price Reconstruction, Multi-Horizon Forecasts, and Directional Traffic Lights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bcb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "from utils.data_manager import DataManager\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "# Setup directories\n",
    "FIGURES = os.path.join(root_path, 'figures')\n",
    "os.makedirs(FIGURES, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d304be",
   "metadata": {},
   "source": [
    "## 1. Setup & Re-Train (Quick Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm = DataManager(data_type='processed', local_dir=os.path.join(root_path, 'data/processed'))\n",
    "# train_df, test_df, scaler = dm.load_processed()\n",
    "\n",
    "# # We need the Linear Regression model (Champion) for detailed plots\n",
    "# X_train = train_df.drop(columns=['Target'])\n",
    "# y_train = train_df['Target']\n",
    "# X_test = test_df.drop(columns=['Target'])\n",
    "# y_test = test_df['Target']\n",
    "\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# preds_scaled = model.predict(X_test)\n",
    "\n",
    "# # Add predictions to test_df for convenience\n",
    "# test_df['Pred_Scaled'] = preds_scaled\n",
    "\n",
    "dm = DataManager(data_type='processed', local_dir=os.path.join(root_path, 'data/processed'))\n",
    "train_df, test_df, scaler = dm.load_processed()\n",
    "\n",
    "# Use the same feature selection as in 03_train_models.ipynb\n",
    "target_col = 'Target'\n",
    "exclude_cols = [target_col, 'Return_Unscaled', 'Close_Unscaled']\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "# We need the Linear Regression model (Champion) for detailed plots\n",
    "X_train = train_df[feature_cols]  # Use only the 13 features\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df[feature_cols]    # Use only the 13 features\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "preds_scaled = model.predict(X_test)\n",
    "\n",
    "# Add predictions to test_df for convenience\n",
    "test_df['Pred_Scaled'] = preds_scaled\n",
    "\n",
    "print(f\"\\nModel trained with {len(feature_cols)} features\")\n",
    "print(f\"Number of coefficients: {len(model.coef_)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda7927",
   "metadata": {},
   "source": [
    "## 2. Price Reconstruction ($P_{t+1} = P_t * (1 + R_{t+1})$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c39415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need 'Close' price unscaled. \n",
    "# Option A: Inverse transform the scaled Close if it is in features.\n",
    "# Option B: Load raw data and align indices. -> Safest.\n",
    "\n",
    "dm_raw = DataManager(data_type='raw', local_dir=os.path.join(root_path, 'data/raw'))\n",
    "df_raw = dm_raw.get_latest_data()\n",
    "if not df_raw.empty:\n",
    "    # Tuple-String Cleanup\n",
    "    new_cols = []\n",
    "    for c in df_raw.columns:\n",
    "        c = str(c)\n",
    "        if (c.startswith(\"('\") or c.startswith('(\"')) and \",\" in c:\n",
    "            clean = c.strip(\"()\").replace(\"'\", \"\").replace('\"', \"\").split(\",\")[0].strip()\n",
    "            new_cols.append(clean)\n",
    "        else:\n",
    "            new_cols.append(c)\n",
    "    df_raw.columns = new_cols\n",
    "    \n",
    "    # Deduplicate\n",
    "    df_raw = df_raw.loc[:, ~df_raw.columns.duplicated()]\n",
    "# Filter to Test Index\n",
    "test_raw = df_raw.loc[test_df.index]\n",
    "\n",
    "# Ensure alignment\n",
    "common_idx = test_df.index.intersection(test_raw.index)\n",
    "test_raw = test_raw.loc[common_idx]\n",
    "preds_aligned = test_df.loc[common_idx, 'Pred_Scaled'] \n",
    "\n",
    "# BUT: Pred_Scaled is a scaled Return? Or is Target scaled? \n",
    "# In Preprocess, 'Target' was just shifted 'Return'.\n",
    "# And 'Return' was scaled using MinMaxScaler.\n",
    "# So we must INVERSE TRANSFORM the predicted return first.\n",
    "\n",
    "# Create a dummy array with same shape as scaler input\n",
    "# We need to know which column index 'Return' was.\n",
    "#feature_cols = X_train.columns.tolist()\n",
    "# 'Return' is likely one of them.\n",
    "# However, usually Target is scaled separately or implicitly if it's derived from scaled cols.\n",
    "# Wait, in 02_preprocess.py:\n",
    "# train_df[feature_cols] = scaler.fit_transform(...)\n",
    "# Target was NOT in feature_cols list during scaling (it was created as shift(-1)).\n",
    "# BUT, train_df was assigned: train_df[feature_cols] = ...\n",
    "# Did we scale 'Target'?\n",
    "# Answer: No, based on 02_preprocess.py, only `feature_cols` were scaled.\n",
    "# Target was left as raw return? \n",
    "# Check 02_preprocess.py lines 117-119:\n",
    "# train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "# Target is created at line 77.\n",
    "# So columns NOT in feature_cols (Target) remain unscaled.\n",
    "# THEREFORE: preds_scaled are actually Unscaled Returns (Predicted).\n",
    "# CONFIRMATION needed. If Target wasn't scaled, then it's raw percentage return (~0.001 etc).\n",
    "\n",
    "# Assuming it is UNSCALED returns (Pct change).\n",
    "pred_returns = preds_scaled\n",
    "\n",
    "# Reconstruct Price\n",
    "# Price_t = raw Close at t.\n",
    "# Price_{t+1} (Predicted) = Price_t * (1 + Pred_Return_{t+1})\n",
    "# Note: Pred_Return_{t+1} is the prediction made at t for t+1. \n",
    "# Index of pred_returns matches X_test index (t).\n",
    "# So test_raw['Close'] is Price_t.\n",
    "# We predict Price_{t+1}.\n",
    "\n",
    "test_raw['Predicted_Close'] = test_raw['Close'] * (1 + pred_returns)\n",
    "\n",
    "# Shift validation\n",
    "# The 'Target' at index t is Return_{t+1}.\n",
    "# The Close at index t is Price_t.\n",
    "# The Actual Close at t+1 is Price_{t+1}.\n",
    "test_raw['Actual_Next_Close'] = test_raw['Close'].shift(-1)\n",
    "test_raw['Predicted_Next_Close'] = test_raw['Close'] * (1 + pred_returns)\n",
    "\n",
    "# Drop last nan\n",
    "test_plot = test_raw.dropna()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(test_plot.index, test_plot['Actual_Next_Close'], label='Actual Price', color='black', alpha=0.6)\n",
    "plt.plot(test_plot.index, test_plot['Predicted_Next_Close'], label='Predicted Price (1-Step)', color='blue', linestyle='--', alpha=0.8)\n",
    "plt.title(\"Price Reconstruction: Actual vs Predicted (1-Day Ahead)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1ebf9",
   "metadata": {},
   "source": [
    "## 3. Zoomed-In Plots (Last 30 Days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_30 = test_plot.iloc[-30:]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(last_30.index, last_30['Actual_Next_Close'], marker='o', label='Actual')\n",
    "plt.plot(last_30.index, last_30['Predicted_Next_Close'], marker='x', linestyle='--', label='Predicted')\n",
    "plt.title(\"Last 30 Days: Price Prediction Zoom\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f2d41a",
   "metadata": {},
   "source": [
    "## 4. Multi-Horizon Forecast (1d, 5d, 10d)\n",
    "\n",
    "Iterative forecasting using Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Refit/Predict Logic for Multi-Horizon\n",
    "# We take a specific start point (e.g., 20 days ago) and forecast 10 days out without seeing seeing ground truth?\n",
    "# Or just predicting T+1, T+5, T+10 using direct models (training separate models for Horizon=5)?\n",
    "# \"Recursive forecasting\" usually means using Pred_T+1 as input for Pred_T+2.\n",
    "\n",
    "# Let's simple recursive with current LR model. \n",
    "# Warning: Features need to be updated. If Features include Lag_1, Lag_2...\n",
    "# We need to feed back our predicted return into the lags.\n",
    "\n",
    "def recursive_forecast(model, initial_row_features, n_steps, feature_names):\n",
    "    # This is complex because features include MA_5, RSI, etc. which depend on PRICE history.\n",
    "    # To do this correctly, we need to reconstruct the PRICE, update MAs/RSI, checks Lags, then Predict.\n",
    "    # Simplified: Only update Lags if they are the main drivers, or assume others constant (bad).\n",
    "    # Correct way: Re-generate all features from the new simulated history.\n",
    "    \n",
    "    # Setup\n",
    "    history_prices = test_df['Close'].iloc[-100:].values.flatten().tolist() # need unscaled or reconstructed?\n",
    "    # Actually we need raw prices to calc features.\n",
    "    # This might be too heavy for this cell. \n",
    "    \n",
    "    # Alternative: Direct Horizon Models.\n",
    "    # Train separate LR models for Target_1d, Target_5d, Target_10d.\n",
    "    return []\n",
    "\n",
    "# NOTE: Implementing Direct Horizon prediction for visualization simplicity and robustness.\n",
    "print(\"Training Multi-Horizon Models (Direct Method)...\")\n",
    "\n",
    "horizons = [1, 5, 10]\n",
    "horizon_preds = {}\n",
    "\n",
    "for h in horizons:\n",
    "    # Create target shifted by h\n",
    "    # Target_h = Returns over h days or Return at day t+h? \n",
    "    # Usually \"Forecast 5 days out\" means Price_{t+5}.\n",
    "    # So we predict Return_{t+5} (accumulated or single day?). \n",
    "    # Let's predict Accumulative Return for h days -> (Price_{t+h} - Price_t) / Price_t\n",
    "    \n",
    "    y_h = train_df['Close_Unscaled'].pct_change(periods=h).shift(-h) # Look ahead h\n",
    "    \n",
    "    # Handle Inf/NaN\n",
    "    y_h = y_h.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Align\n",
    "    valid_idx = y_h.dropna().index.intersection(X_train.index)\n",
    "    X_h = X_train.loc[valid_idx]\n",
    "    y_h = y_h.loc[valid_idx]\n",
    "    \n",
    "    model_h = LinearRegression()\n",
    "    model_h.fit(X_h, y_h)\n",
    "    \n",
    "    # Predict on Test\n",
    "    # Test alignment\n",
    "    y_test_h = test_df['Close_Unscaled'].pct_change(periods=h).shift(-h)\n",
    "    y_test_h = y_test_h.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    valid_test_idx = y_test_h.dropna().index.intersection(X_test.index)\n",
    "    \n",
    "    X_test_h = X_test.loc[valid_test_idx]\n",
    "    pred_h = model_h.predict(X_test_h)\n",
    "    \n",
    "    # Reconstruct Price\n",
    "    # Price_{t+h} = Price_t * (1 + Pred_Return_h)\n",
    "    base_prices = test_df.loc[valid_test_idx, 'Close_Unscaled']\n",
    "    price_pred_h = base_prices * (1 + pred_h)\n",
    "    price_actual_h = base_prices * (1 + y_test_h.loc[valid_test_idx])\n",
    "    \n",
    "    horizon_preds[h] = (valid_test_idx, price_actual_h, price_pred_h)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "last_n = 50\n",
    "idx = horizon_preds[1][0][-last_n:] # Use 1d index as base\n",
    "\n",
    "plt.plot(idx, horizon_preds[1][1][-last_n:], label='Actual Future Price', color='black', alpha=0.3, linewidth=3)\n",
    "\n",
    "colors = {1:'blue', 5:'orange', 10:'red'}\n",
    "for h in horizons:\n",
    "    p_idx = horizon_preds[h][0][-last_n:]\n",
    "    p_vals = horizon_preds[h][2][-last_n:]\n",
    "    # Shift plotting? \n",
    "    # No, at time t we predict t+h. \n",
    "    # If we plot at time t, it shows \"what we thought t+h would be\".\n",
    "    # Or we plot the prediction at time t+h?\n",
    "    # Convention: Plot at target time.\n",
    "    # So we shift the index by h days?\n",
    "    \n",
    "    # Let's plot at TARGET time\n",
    "    # This requires shifting index.\n",
    "    \n",
    "    # Using simple shift for viz (approx business days)\n",
    "    # plot_idx = [d + timedelta(days=h) for d in p_idx] # Timedelta might fail on RangeIndex\n",
    "    # Let's just plot 'What we predict next' overlaid on current.\n",
    "    \n",
    "    plt.plot(p_idx, p_vals, label=f'{h}-Day Forecast', color=colors[h], marker='.', linestyle=':')\n",
    "\n",
    "plt.title(\"Multi-Horizon Forecasts (Price Predicted at t for t+h)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a15ef",
   "metadata": {},
   "source": [
    "## 5. Directional Accuracy Traffic Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "actual_dir = np.sign(test_plot['Actual_Next_Close'] - test_plot['Close'])\n",
    "pred_dir = np.sign(test_plot['Predicted_Next_Close'] - test_plot['Close'])\n",
    "\n",
    "cm = confusion_matrix(actual_dir, pred_dir, labels=[1, -1])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', xticklabels=['Up', 'Down'], yticklabels=['Up', 'Down'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Directional Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Traffic Light Plot\n",
    "# Green dot if Correct Direction, Red if Wrong.\n",
    "correct_mask = (actual_dir == pred_dir)\n",
    "wrong_mask = (actual_dir != pred_dir)\n",
    "\n",
    "subset = test_plot.iloc[-100:]\n",
    "sub_correct = correct_mask.loc[subset.index]\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(subset.index, subset['Actual_Next_Close'], color='black', alpha=0.5, label='Price')\n",
    "\n",
    "# Plot Correct predictions (Green)\n",
    "plt.scatter(subset[sub_correct].index, subset[sub_correct]['Actual_Next_Close'], color='green', label='Correct Dir', s=50)\n",
    "\n",
    "# Plot Wrong predictions (Red)\n",
    "plt.scatter(subset[~sub_correct].index, subset[~sub_correct]['Actual_Next_Close'], color='red', label='Wrong Dir', s=50)\n",
    "\n",
    "plt.title(\"Directional Accuracy Traffic Light (Green=Correct, Red=Wrong)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347197b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis for Linear Regression\n",
    "# Adapted from Random Forest feature importance code\n",
    "\n",
    "print(\"\\nüéØ Feature Importance Analysis (Linear Regression)\")\n",
    "\n",
    "# Use the same feature selection as in training (03_train_models.ipynb)\n",
    "target_col = 'Target'\n",
    "exclude_cols = [target_col, 'Return_Unscaled', 'Close_Unscaled']\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"Number of coefficients: {len(model.coef_)}\")\n",
    "\n",
    "# Linear Regression uses coefficients instead of feature_importances_\n",
    "if hasattr(model, 'coef_'):\n",
    "    # Get absolute values of coefficients as importance measure\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Coefficient': model.coef_,\n",
    "        'Abs_Coefficient': np.abs(model.coef_)\n",
    "    }).sort_values('Abs_Coefficient', ascending=False)\n",
    "    \n",
    "    print(f\"\\nAll {len(feature_importance)} Features (by absolute coefficient):\")\n",
    "    for idx, row in feature_importance.iterrows():\n",
    "        print(f\"  {row['Feature']:25}: {row['Coefficient']:10.4f} (|{row['Abs_Coefficient']:.4f}|)\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors)\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.title(f'Feature Importances - Linear Regression ({len(feature_cols)} features)\\nGreen=Positive, Red=Negative')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    feature_importance_path = os.path.join(FIGURES, 'ml_feature_importance_lr.png')\n",
    "    plt.savefig(feature_importance_path, dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Feature importance plot saved to: {feature_importance_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Feature importance not available for Linear Regression model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_eurusd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
